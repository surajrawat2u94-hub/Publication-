name: Fetch Publications (OpenAlex → institution_data.json)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "30 20 * * *"

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      ROR: ${{ secrets.INSTITUTION_ROR }}        # e.g. 04q2jes40
      CONTACT: ${{ secrets.CONTACT_EMAIL }}      # e.g. yourname@gmail.com
      FROM_YEAR: "2010"
      PER_PAGE: "50"                             # smaller page reduces blocks
      PAGES_MAX: "200"
      OUTFILE: "institution_data.json"

    steps:
      - uses: actions/checkout@v4

      - name: Validate secrets (fail fast)
        shell: bash
        run: |
          if [ -z "${ROR}" ]; then echo "❌ Missing INSTITUTION_ROR secret"; exit 1; fi
          if [ -z "${CONTACT}" ]; then echo "❌ Missing CONTACT_EMAIL secret"; exit 1; fi
          if ! echo "${CONTACT}" | grep -Eq '^[^@]+@[^@]+\.[^@]+$'; then
            echo "❌ CONTACT_EMAIL does not look like an email"; exit 1; fi
          # Basic ROR sanity (9 chars, lowercase/number); adjust if your ROR differs
          if ! echo "${ROR}" | grep -Eq '^[0-9a-z]{9}$'; then
            echo "⚠️ ROR looks unusual. Continuing, but double-check the value."; fi
          echo "::add-mask::${CONTACT}"
          echo "✅ Secrets present. Proceeding…"

      - name: Fetch with polite headers + Retry-After
        shell: bash
        run: |
          node - <<'NODE'
          const https = require("https");
          const fs = require("fs");

          const ROR       = process.env.ROR;
          const CONTACT   = process.env.CONTACT;
          const FROM      = `${process.env.FROM_YEAR || "2010"}-01-01`;
          const TO        = `${new Date().getFullYear()}-12-31`;
          const PER_PAGE  = parseInt(process.env.PER_PAGE || "50", 10);
          const PAGES_MAX = parseInt(process.env.PAGES_MAX || "200", 10);
          const OUTFILE   = process.env.OUTFILE || "institution_data.json";
          const UA        = `Institution Sync (+mailto:${CONTACT})`;

          function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }
          function redactedUrl(u){ return u.replace(encodeURIComponent(CONTACT), "hidden%40example.org"); }

          async function fetchPage(cursor, attempt=1){
            const qs = new URLSearchParams({
              "per-page": String(PER_PAGE),
              "cursor": cursor,
              "mailto": CONTACT,
              "filter": `institutions.ror:${ROR},from_publication_date:${FROM},to_publication_date:${TO}`,
              "select": "id,doi,title,authorships,host_venue,publication_year,type,cited_by_count,primary_location,is_retracted"
            }).toString();
            const url = `https://api.openalex.org/works?${qs}`;
            console.log("GET", redactedUrl(url));

            return new Promise((resolve, reject)=>{
              const req = https.get(url, {
                headers: {
                  "User-Agent": UA,
                  "From": CONTACT,
                  "Accept": "application/json",
                  "Connection": "close"
                }
              }, async (res)=>{
                let d=""; res.on("data", c=>d+=c);
                res.on("end", async ()=>{
                  const retryAfter = parseInt(res.headers["retry-after"]||"0",10)*1000 || 0;

                  if (res.statusCode === 429 || res.statusCode === 403) {
                    const backoff = retryAfter || Math.min(120000, 800 * Math.pow(2, attempt-1));
                    console.log(`HTTP ${res.statusCode}. Backing off ${backoff}ms (attempt ${attempt}) and retrying…`);
                    if (attempt >= 6) return reject(new Error(`OpenAlex ${res.statusCode} after ${attempt} attempts`));
                    await sleep(backoff);
                    try { const again = await fetchPage(cursor, attempt+1); return resolve(again); }
                    catch(e){ return reject(e); }
                  }

                  if (res.statusCode !== 200) {
                    console.error("HTTP", res.statusCode, d.slice(0,300));
                    return reject(new Error(`HTTP ${res.statusCode}`));
                  }

                  let j; try { j = JSON.parse(d); } catch { return reject(new Error("Invalid JSON")); }

                  const items = (j.results||[]).map(w=>{
                    const doi=(w.doi||"").replace(/^https?:\/\/doi\.org\//i,"");
                    return {
                      doi,
                      title: w.title || "",
                      year: w.publication_year || null,
                      type: w.type || "",
                      citations: w.cited_by_count || 0,
                      authors: (w.authorships||[]).map(a=>a.author?.display_name).filter(Boolean),
                      journal: w.host_venue?.display_name || "",
                      issns: (w.host_venue?.issn || []).map(x=>(x||"").toUpperCase()),
                      url: w.primary_location?.landing_page_url || (doi?`https://doi.org/${doi}`:""),
                      is_retracted: !!w.is_retracted
                    };
                  });

                  resolve({ items, next: j?.meta?.next_cursor || null });
                });
              });
              req.on("error", reject);
            });
          }

          (async ()=>{
            let cursor="*";
            let page=0;
            const all=[];
            let firstPageTries=0;

            while (cursor && page < PAGES_MAX) {
              page++;
              console.log(`Fetching page ${page}…`);
              try {
                const {items, next} = await fetchPage(cursor);
                console.log(`→ ${items.length} records`);
                all.push(...items);
                if (!items.length) break;
                cursor = next;
                await sleep(500); // small politeness delay
              } catch (e) {
                if (page === 1) {
                  firstPageTries++;
                  console.error(`First page failed: ${e.message}`);
                  if (firstPageTries >= 2) {
                    console.error("Still blocked on first page.\n• Re-check CONTACT_EMAIL and INSTITUTION_ROR secrets\n• Try PER_PAGE=25\n• Try running the local script (see instructions)");
                    process.exit(1);
                  }
                  page--; await sleep(2000); continue;
                }
                console.error("Fetch failed:", e.message);
                process.exit(1);
              }
            }

            const out = { updated: new Date().toISOString(), count: all.length, items: all };
            fs.writeFileSync(OUTFILE, JSON.stringify(out,null,2));
            console.log(`Saved ${all.length} records → ${OUTFILE}`);
          })();
          NODE

      - name: Commit JSON
        run: |
          if git status --porcelain | grep -q "${OUTFILE:-institution_data.json}"; then
            git config user.name "github-actions"
            git config user.email "actions@users.noreply.github.com"
            git add "${OUTFILE:-institution_data.json}"
            git commit -m "Update publication dump"
            git push
          else
            echo "No changes"
          fi
