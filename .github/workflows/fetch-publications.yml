name: Fetch Publications (OpenAlex → institution_data.json)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "30 20 * * *"

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      ROR: ${{ secrets.INSTITUTION_ROR }}        # e.g. 04q2jes40
      CONTACT: ${{ secrets.CONTACT_EMAIL }}      # e.g. yourname@gmail.com
      FROM_YEAR: "2010"
      PER_PAGE: "100"                            # ↓ smaller page reduces blocks
      PAGES_MAX: "120"
      OUTFILE: "institution_data.json"

    steps:
      - uses: actions/checkout@v4

      - name: Sanity-check secrets are present
        run: |
          if [ -z "${ROR}" ]; then echo "Missing INSTITUTION_ROR secret"; exit 1; fi
          if [ -z "${CONTACT}" ]; then echo "Missing CONTACT_EMAIL secret"; exit 1; fi
          echo "Secrets look set (values are masked)."

      - name: Fetch with polite headers, Retry-After, and capped retries
        shell: bash
        run: |
          node - <<'NODE'
          const https = require("https");
          const fs = require("fs");

          const ROR       = process.env.ROR;
          const CONTACT   = process.env.CONTACT;
          const FROM      = `${process.env.FROM_YEAR || "2010"}-01-01`;
          const TO        = `${new Date().getFullYear()}-12-31`;
          const PER_PAGE  = parseInt(process.env.PER_PAGE || "100", 10);
          const PAGES_MAX = parseInt(process.env.PAGES_MAX || "120", 10);
          const OUTFILE   = process.env.OUTFILE || "institution_data.json";

          const UA = `Institution Sync Bot (+mailto:${CONTACT})`;

          function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }
          function jitter(ms){ return ms + Math.floor(Math.random()*ms*0.25); }

          async function fetchPage(cursor, attempt=1){
            const qs = new URLSearchParams({
              "per-page": String(PER_PAGE),
              "cursor": cursor,
              "mailto": CONTACT,
              "filter": `institutions.ror:${ROR},from_publication_date:${FROM},to_publication_date:${TO}`,
              "select": "id,doi,title,authorships,host_venue,publication_year,type,cited_by_count,primary_location,is_retracted"
            }).toString();
            const url = `https://api.openalex.org/works?${qs}`;
            // console.log("GET", url);  // uncomment if you need to see the URL (email will be masked in logs)

            return new Promise((resolve, reject)=>{
              const req = https.get(url, {
                headers: {
                  "User-Agent": UA,
                  "From": CONTACT,
                  "Accept": "application/json"
                },
              }, async (res)=>{
                let d="";
                res.on("data", c=>d+=c);
                res.on("end", async ()=>{
                  const retryAfterHeader = res.headers["retry-after"];
                  const retryAfterMs = retryAfterHeader ? parseInt(retryAfterHeader,10)*1000 : null;

                  if (res.statusCode === 429 || res.statusCode === 403) {
                    // Respect Retry-After if present, otherwise exp backoff with jitter
                    const base = retryAfterMs ?? (attempt < 6 ? 1000 * Math.pow(2, attempt-1) : 20000);
                    const wait = Math.min(120000, jitter(base)); // cap at 120s
                    console.log(`HTTP ${res.statusCode}. Backing off ${wait}ms (attempt ${attempt}) and retrying…`);
                    if (attempt >= 8) { // hard cap retries on same page
                      return reject(new Error(`OpenAlex ${res.statusCode} after ${attempt} attempts`));
                    }
                    await sleep(wait);
                    try { const again = await fetchPage(cursor, attempt+1); return resolve(again); }
                    catch(e){ return reject(e); }
                  }

                  if (res.statusCode !== 200) {
                    console.error("HTTP", res.statusCode, d.slice(0,400));
                    return reject(new Error(`HTTP ${res.statusCode}`));
                  }

                  let j;
                  try { j = JSON.parse(d); }
                  catch(e){ return reject(new Error("Invalid JSON from OpenAlex")); }

                  const items = (j.results||[]).map(w=>{
                    const doi = (w.doi||"").replace(/^https?:\/\/doi\.org\//i,"");
                    return {
                      doi,
                      title: w.title || "",
                      year: w.publication_year || null,
                      type: w.type || "",
                      citations: w.cited_by_count || 0,
                      authors: (w.authorships||[]).map(a=>a.author?.display_name).filter(Boolean),
                      journal: w.host_venue?.display_name || "",
                      issns: (w.host_venue?.issn || []).map(x=>(x||"").toUpperCase()),
                      url: w.primary_location?.landing_page_url || (doi?`https://doi.org/${doi}`:""),
                      is_retracted: !!w.is_retracted
                    };
                  });

                  resolve({ items, next: j?.meta?.next_cursor || null });
                });
              });
              req.on("error", reject);
            });
          }

          (async ()=>{
            let cursor="*";
            let page=0;
            const all=[];
            let consecutive403onFirstPage = 0;

            while (cursor && page < PAGES_MAX) {
              page++;
              console.log(`Fetching page ${page} (cursor=${cursor === "*" ? "start" : "…"}) …`);
              try {
                const {items, next} = await fetchPage(cursor);
                console.log(`→ ${items.length} records`);
                all.push(...items);
                if (!items.length) break;
                cursor = next;
                await sleep(300); // small politeness delay
              } catch (e) {
                // If it's the very first page and keeps 403-ing, fail fast with guidance
                if (page === 1 && /OpenAlex 4(03|29)/.test(String(e.message))) {
                  consecutive403onFirstPage++;
                  if (consecutive403onFirstPage >= 2) {
                    console.error("Still blocked on first page. Check CONTACT_EMAIL is a real address and INSTITUTION_ROR is valid. Also try reducing PER_PAGE to 50.");
                    process.exit(1);
                  } else {
                    page--; // retry first page loop
                    await sleep(2000);
                    continue;
                  }
                }
                console.error("Failed:", e.message);
                process.exit(1);
              }
            }

            const out = { updated: new Date().toISOString(), count: all.length, items: all };
            fs.writeFileSync(process.env.OUTFILE || "institution_data.json", JSON.stringify(out,null,2));
            console.log(`Saved ${all.length} records → ${process.env.OUTFILE || "institution_data.json"}`);
          })();
          NODE

      - name: Commit JSON
        run: |
          if git status --porcelain | grep -q "${OUTFILE:-institution_data.json}"; then
            git config user.name "github-actions"
            git config user.email "actions@users.noreply.github.com"
            git add "${OUTFILE:-institution_data.json}"
            git commit -m "Update publication dump"
            git push
          else
            echo "No changes to commit"
          fi
